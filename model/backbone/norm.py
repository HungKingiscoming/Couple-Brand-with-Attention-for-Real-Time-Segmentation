"""
====================================================================
GIáº¢I PHÃP HOÃ€N CHá»ˆNH: FIX MISSING BN RUNNING STATS
====================================================================

NGUYÃŠN NHÃ‚N:
- Train code convert BN â†’ GN
- NhÆ°ng checkpoint láº¡i cÃ³ BN keys
- BN keys KHÃ”NG cÃ³ running_mean/running_var
- Eval mode dÃ¹ng default stats (0/1) â†’ mIoU = 0

GIáº¢I PHÃP:
1. TRAIN: Äáº£m báº£o lÆ°u Ä‘Ãºng norm type
2. EVAL: Warmup BN stats trÆ°á»›c khi eval
3. INFERENCE: DÃ¹ng Ä‘Ãºng norm type nhÆ° training
====================================================================
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from tqdm import tqdm
import numpy as np
from typing import Optional, Dict


# ============================================================
# SOLUTION 1: FIX TRAINING - LÆ¯U CHECKPOINT ÄÃšNG
# ============================================================

def save_checkpoint_with_correct_norm(
    model: nn.Module,
    optimizer,
    scheduler,
    scaler,
    epoch: int,
    metrics: dict,
    save_path: str,
    global_step: int = 0,
    best_miou: float = 0.0
):
    """
    âœ… FIXED: Save checkpoint vá»›i Ä‘Ãºng norm type + running stats
    
    Thay tháº¿ hÃ m save_checkpoint cÅ© trong Trainer
    """
    
    # Detect norm type
    has_bn = any(isinstance(m, (nn.BatchNorm2d, nn.SyncBatchNorm)) 
                for m in model.modules())
    has_gn = any(isinstance(m, nn.GroupNorm) 
                for m in model.modules())
    
    print(f"\nğŸ“¦ Saving checkpoint...")
    print(f"   Norm type: {'BatchNorm' if has_bn else 'GroupNorm' if has_gn else 'Unknown'}")
    
    # Get state dict
    state_dict = model.state_dict()
    
    # Verify BN running stats if using BN
    if has_bn:
        bn_stats_count = sum(1 for k in state_dict.keys() 
                            if 'running_mean' in k or 'running_var' in k)
        print(f"   BN running stats: {bn_stats_count} tensors")
        
        if bn_stats_count == 0:
            print(f"   âš ï¸  WARNING: BatchNorm detected but NO running stats!")
            print(f"   This checkpoint will NOT work in eval mode!")
    
    checkpoint = {
        'epoch': epoch,
        'model': state_dict,
        'optimizer': optimizer.state_dict(),
        'scheduler': scheduler.state_dict() if scheduler else None,
        'scaler': scaler.state_dict(),
        'best_miou': best_miou,
        'metrics': metrics,
        'global_step': global_step,
        # âœ… THÃŠM metadata Ä‘á»ƒ debug
        'norm_type': 'BatchNorm' if has_bn else 'GroupNorm' if has_gn else 'Mixed',
        'has_running_stats': bn_stats_count > 0 if has_bn else False,
    }
    
    torch.save(checkpoint, save_path)
    print(f"   âœ… Saved: {save_path}")


# ============================================================
# SOLUTION 2: WARMUP BN RUNNING STATS
# ============================================================

@torch.no_grad()
def warmup_bn_stats(
    model: nn.Module,
    dataloader: DataLoader,
    device: str = 'cuda',
    num_batches: int = 100,
    reset_stats: bool = True
):
    """
    âœ… Warmup BatchNorm running statistics
    
    KHI NÃ€O Cáº¦N:
    - Checkpoint khÃ´ng cÃ³ running_mean/running_var
    - Hoáº·c chuyá»ƒn tá»« GN checkpoint sang BN model
    - Hoáº·c model train vá»›i BN nhÆ°ng chÆ°a cÃ³ stats
    
    Args:
        model: Model cáº§n warmup
        dataloader: Train/Val dataloader
        device: 'cuda' or 'cpu'
        num_batches: Sá»‘ batch Ä‘á»ƒ collect stats (100-200 lÃ  Ä‘á»§)
        reset_stats: Reset stats vá» 0 trÆ°á»›c khi warmup
    """
    print("=" * 70)
    print("ğŸ”¥ WARMING UP BATCHNORM RUNNING STATISTICS")
    print("=" * 70)
    
    # Check if model has BN
    bn_layers = [m for m in model.modules() 
                if isinstance(m, (nn.BatchNorm2d, nn.SyncBatchNorm))]
    
    if not bn_layers:
        print("âš ï¸  No BatchNorm layers found! Skipping warmup.")
        return
    
    print(f"ğŸ“Š Found {len(bn_layers)} BatchNorm layers")
    print(f"ğŸ”„ Processing {num_batches} batches...")
    
    # Set to train mode (CRITICAL!)
    model.train()
    
    # Reset stats if needed
    if reset_stats:
        for m in bn_layers:
            if hasattr(m, 'reset_running_stats'):
                m.reset_running_stats()
            # Use cumulative moving average (no momentum)
            m.momentum = None
    
    # Collect stats
    num_processed = 0
    for batch_idx, batch in enumerate(tqdm(dataloader, total=num_batches)):
        if batch_idx >= num_batches:
            break
        
        # Handle different batch formats
        if isinstance(batch, (tuple, list)):
            images = batch[0]
        else:
            images = batch
        
        images = images.to(device)
        
        # Forward pass (no gradient needed)
        _ = model(images)
        num_processed += 1
    
    print(f"\nâœ… Warmup complete! Processed {num_processed} batches")
    
    # Verify stats were updated
    sample_bn = bn_layers[0]
    if hasattr(sample_bn, 'running_mean'):
        mean_val = sample_bn.running_mean.abs().mean().item()
        var_val = sample_bn.running_var.mean().item()
        print(f"   Sample stats: mean={mean_val:.4f}, var={var_val:.4f}")
        
        if mean_val < 1e-6 and abs(var_val - 1.0) < 1e-6:
            print(f"   âš ï¸  WARNING: Stats look like defaults! May need more batches.")
    
    # Switch back to eval
    model.eval()
    print("=" * 70)


# ============================================================
# SOLUTION 3: COMPLETE EVALUATION WITH BN WARMUP
# ============================================================

@torch.no_grad()
def evaluate_with_bn_warmup(
    model: nn.Module,
    val_loader: DataLoader,
    device: str = 'cuda',
    num_classes: int = 19,
    ignore_index: int = 255,
    warmup_batches: int = 100,
    use_warmup: bool = True
):
    """
    âœ… COMPLETE: Eval vá»›i BN warmup tá»± Ä‘á»™ng
    
    Usage:
        metrics = evaluate_with_bn_warmup(
            model, val_loader, device='cuda',
            warmup_batches=100  # â† TÃ¹y chá»‰nh
        )
    """
    
    # Step 1: Warmup BN if needed
    if use_warmup:
        warmup_bn_stats(
            model, val_loader, device, 
            num_batches=warmup_batches,
            reset_stats=True
        )
    
    # Step 2: Standard evaluation
    print("\n" + "=" * 70)
    print("ğŸ“Š EVALUATING MODEL")
    print("=" * 70)
    
    model.eval()
    confusion_matrix = np.zeros((num_classes, num_classes), dtype=np.int64)
    
    for batch in tqdm(val_loader, desc="Validation"):
        if isinstance(batch, (tuple, list)):
            images, masks = batch[0], batch[1]
        else:
            images, masks = batch, None
        
        images = images.to(device)
        
        # Forward
        if hasattr(model, 'forward_train'):
            outputs = model.forward_train(images)
            logits = outputs.get('main', outputs)
        else:
            logits = model(images)
        
        # Handle dict output
        if isinstance(logits, dict):
            logits = logits.get('c5', logits.get('out', list(logits.values())[0]))
        
        # Resize to match target
        if masks is not None:
            masks = masks.to(device).long()
            if masks.dim() == 4:
                masks = masks.squeeze(1)
            
            H, W = masks.shape[-2:]
            if logits.shape[-2:] != (H, W):
                logits = F.interpolate(
                    logits, size=(H, W), 
                    mode='bilinear', align_corners=False
                )
            
            # Predictions
            preds = logits.argmax(1).cpu().numpy()
            targets = masks.cpu().numpy()
            
            # Update confusion matrix
            mask = (targets >= 0) & (targets < num_classes)
            label = num_classes * targets[mask].astype('int') + preds[mask]
            count = np.bincount(label, minlength=num_classes**2)
            confusion_matrix += count.reshape(num_classes, num_classes)
    
    # Compute metrics
    intersection = np.diag(confusion_matrix)
    union = confusion_matrix.sum(1) + confusion_matrix.sum(0) - intersection
    iou = intersection / (union + 1e-10)
    
    miou = np.nanmean(iou)
    acc = intersection.sum() / (confusion_matrix.sum() + 1e-10)
    
    print(f"\nâœ… Evaluation Results:")
    print(f"   mIoU: {miou:.4f}")
    print(f"   Acc:  {acc:.4f}")
    print("=" * 70)
    
    return {
        'miou': miou,
        'accuracy': acc,
        'per_class_iou': iou,
        'confusion_matrix': confusion_matrix
    }


# ============================================================
# SOLUTION 4: FIX EXISTING CHECKPOINT (EMERGENCY)
# ============================================================

def fix_checkpoint_add_bn_stats(
    checkpoint_path: str,
    output_path: str,
    model: nn.Module,
    dataloader: DataLoader,
    device: str = 'cuda',
    warmup_batches: int = 200
):
    """
    âœ… EMERGENCY: Sá»­a checkpoint cÅ© - ThÃªm BN running stats
    
    KHI NÃ€O DÃ™NG:
    - ÄÃ£ train xong nhÆ°ng checkpoint thiáº¿u BN stats
    - KhÃ´ng muá»‘n train láº¡i
    - CÃ³ dataloader Ä‘á»ƒ collect stats
    
    Args:
        checkpoint_path: Checkpoint cÅ© (thiáº¿u stats)
        output_path: Checkpoint má»›i (cÃ³ stats)
        model: Model architecture (chÆ°a load weight)
        dataloader: Dataloader Ä‘á»ƒ collect stats
        warmup_batches: Sá»‘ batch Ä‘á»ƒ collect
    """
    print("=" * 70)
    print("ğŸ”§ FIXING CHECKPOINT: ADDING BN RUNNING STATS")
    print("=" * 70)
    
    # Load old checkpoint
    print(f"\nğŸ“¥ Loading: {checkpoint_path}")
    ckpt = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
    
    # Load weights to model
    model.load_state_dict(ckpt['model'], strict=False)
    model = model.to(device)
    
    # Warmup BN
    print(f"\nğŸ”¥ Collecting BN stats from {warmup_batches} batches...")
    warmup_bn_stats(model, dataloader, device, warmup_batches, reset_stats=True)
    
    # Get new state dict with stats
    new_state_dict = model.state_dict()
    
    # Count stats
    stats_count = sum(1 for k in new_state_dict.keys() 
                     if 'running_mean' in k or 'running_var' in k)
    
    print(f"\nğŸ“Š New checkpoint will have:")
    print(f"   Total keys: {len(new_state_dict)}")
    print(f"   BN running stats: {stats_count} tensors")
    
    # Update checkpoint
    ckpt['model'] = new_state_dict
    ckpt['fixed'] = True
    ckpt['fixed_info'] = {
        'original_path': checkpoint_path,
        'warmup_batches': warmup_batches,
        'has_running_stats': stats_count > 0
    }
    
    # Save
    torch.save(ckpt, output_path)
    print(f"\nâœ… Fixed checkpoint saved: {output_path}")
    print("=" * 70)


# ============================================================
# SOLUTION 5: RECOMMENDED TRAINING WORKFLOW
# ============================================================

def recommended_training_modifications():
    """
    HÆ°á»›ng dáº«n sá»­a train.py Ä‘á»ƒ trÃ¡nh váº¥n Ä‘á» nÃ y
    """
    
    print("=" * 70)
    print("ğŸ“˜ RECOMMENDED MODIFICATIONS TO train.py")
    print("=" * 70)
    
    print("""
OPTION 1: TRAIN Vá»šI GROUPNORM (ÄÆ N GIáº¢N NHáº¤T)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Æ¯u Ä‘iá»ƒm:
   - KhÃ´ng cáº§n running stats
   - Stable vá»›i batch size nhá»
   - Inference Ä‘Æ¡n giáº£n

ğŸ“ Code changes:

# Line ~790 trong train.py - GIá»® NGUYÃŠN
model = replace_bn_with_gn(model)  # â† GIá»® DÃ’NG NÃ€Y

# Line ~950 trong save_checkpoint - THÃŠM VERIFY
save_checkpoint_with_correct_norm(...)  # â† DÃ™NG HÃ€M Má»šI

# Inference code
model = replace_bn_with_gn(model)
model.load_state_dict(checkpoint['model'])
model.eval()
output = model(input)  # â† XONG!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


OPTION 2: TRAIN Vá»šI BATCHNORM (Náº¾U BATCH SIZE Lá»šN â‰¥16)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸  LÆ°u Ã½:
   - Cáº§n Ä‘áº£m báº£o BN á»Ÿ train mode khi train
   - Checkpoint Tá»° Äá»˜NG cÃ³ running stats
   - Eval mode hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng

ğŸ“ Code changes:

# Line ~790 trong train.py - XÃ“A HOáº¶C COMMENT
# model = replace_bn_with_gn(model)  # â† XÃ“A DÃ’NG NÃ€Y!

# Hoáº·c thÃªm flag
if args.use_groupnorm:  # â† THÃŠM ARG Má»šI
    model = replace_bn_with_gn(model)

# Line ~950 - VERIFY STATS
save_checkpoint_with_correct_norm(...)

# Inference code - ÄÆ N GIáº¢N
model.load_state_dict(checkpoint['model'])
model.eval()  # â† BN tá»± Ä‘á»™ng dÃ¹ng running stats
output = model(input)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


OPTION 3: HYBRID - TRAIN BN, EVAL GN (ADVANCED)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ Khi nÃ o dÃ¹ng:
   - Train batch lá»›n (BN tá»‘t hÆ¡n)
   - Inference batch nhá»/variable (GN á»•n Ä‘á»‹nh hÆ¡n)

ğŸ“ Code:

# Training - KHÃ”NG convert
# (model giá»¯ nguyÃªn BN)

# Inference - Convert checkpoint
from convert_utils import convert_bn_to_gn_checkpoint

# Load BN checkpoint
ckpt = torch.load('checkpoint_bn.pth')

# Convert to GN
gn_state_dict = convert_bn_to_gn_checkpoint(ckpt['model'])

# Load vÃ o GN model
model_gn = replace_bn_with_gn(model)
model_gn.load_state_dict(gn_state_dict)
model_gn.eval()

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")


# ============================================================
# EMERGENCY USAGE FOR YOUR CURRENT CHECKPOINT
# ============================================================

def emergency_fix_your_checkpoint():
    """
    HÆ°á»›ng dáº«n fix checkpoint hiá»‡n táº¡i cá»§a báº¡n
    """
    
    print("\n" + "=" * 70)
    print("ğŸš¨ EMERGENCY FIX FOR YOUR CURRENT CHECKPOINT")
    print("=" * 70)
    
    print("""
Checkpoint cá»§a báº¡n: /kaggle/input/test-data12/weight_test.pth
Váº¥n Ä‘á»: CÃ³ BN keys nhÆ°ng KHÃ”NG cÃ³ running_mean/running_var

GIáº¢I PHÃP NHANH (KhÃ´ng cáº§n train láº¡i):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import torch
from your_model import build_model
from data.custom import create_dataloaders

# 1. Build model (match training config)
model = build_model(...)

# 2. Load checkpoint
ckpt = torch.load('weight_test.pth')
model.load_state_dict(ckpt['model'], strict=False)

# 3. Get dataloader
_, val_loader, _ = create_dataloaders(...)

# 4. Fix checkpoint - thÃªm BN stats
fix_checkpoint_add_bn_stats(
    checkpoint_path='weight_test.pth',
    output_path='weight_test_fixed.pth',
    model=model,
    dataloader=val_loader,
    device='cuda',
    warmup_batches=200  # â† 200 batches = ~1600 images
)

# 5. Eval vá»›i checkpoint má»›i
model_new = build_model(...)
ckpt_new = torch.load('weight_test_fixed.pth')
model_new.load_state_dict(ckpt_new['model'])

metrics = evaluate_with_bn_warmup(
    model_new, val_loader,
    use_warmup=False  # â† ÄÃ£ cÃ³ stats rá»“i
)

print(f"mIoU: {metrics['miou']:.4f}")

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")


if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("ğŸ“š COMPLETE SOLUTION GUIDE")
    print("=" * 70)
    
    # Show recommended workflow
    recommended_training_modifications()
    
    # Show emergency fix
    emergency_fix_your_checkpoint()
    
    print("\n" + "=" * 70)
    print("ğŸ’¡ WHAT TO DO NOW:")
    print("=" * 70)
    print("""
1ï¸âƒ£ NGAY Láº¬P Tá»¨C (Fix checkpoint hiá»‡n táº¡i):
   â†’ DÃ¹ng fix_checkpoint_add_bn_stats()
   â†’ Hoáº·c warmup BN khi eval: evaluate_with_bn_warmup()

2ï¸âƒ£ DÃ€I Háº N (Training má»›i):
   â†’ Option 1: Train vá»›i GN (recommended cho batch nhá»)
   â†’ Option 2: Train vá»›i BN (náº¿u batch â‰¥16)
   â†’ Verify checkpoint trÆ°á»›c khi lÆ°u

3ï¸âƒ£ INFERENCE (Production):
   â†’ Äáº£m báº£o model + checkpoint cÃ¹ng norm type
   â†’ BN: Cáº§n .eval() mode
   â†’ GN: KhÃ´ng cáº§n eval/train mode
""")
