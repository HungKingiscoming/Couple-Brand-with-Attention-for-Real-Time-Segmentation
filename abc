#!/usr/bin/env python3
"""
Checkpoint Adapter - Adapt old checkpoints to new model structure
Handles:
1. Missing fake_proj layers (initialize from c1/c2_proj)
2. BN â†’ no-BN conversion (fuse BN into conv bias)
3. FP16 â†’ FP32 conversion
"""

import torch
import torch.nn as nn
import argparse


def fuse_bn_into_conv(conv_weight, bn_weight, bn_bias, bn_running_mean, bn_running_var, bn_eps=1e-5):
    """
    Fuse BatchNorm parameters into Conv layer
    Returns: fused_weight, fused_bias
    """
    # BN formula: (x - mean) / sqrt(var + eps) * gamma + beta
    # We want to fuse this into: conv_weight * x + conv_bias
    
    std = torch.sqrt(bn_running_var + bn_eps)
    
    # Fused weight = conv_weight * (gamma / std)
    fused_weight = conv_weight * (bn_weight / std).reshape(-1, 1, 1, 1)
    
    # Fused bias = beta - (mean * gamma / std)
    fused_bias = bn_bias - (bn_running_mean * bn_weight / std)
    
    return fused_weight, fused_bias


def adapt_checkpoint(ckpt_path, output_path):
    """
    Adapt checkpoint to current model structure
    """
    print(f"\n{'='*70}")
    print("ðŸ”§ CHECKPOINT ADAPTER")
    print(f"{'='*70}\n")
    
    print(f"Input:  {ckpt_path}")
    print(f"Output: {output_path}")
    
    # Load checkpoint
    ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=False)
    
    if 'model' in ckpt:
        state_dict = ckpt['model']
    else:
        state_dict = ckpt
    
    print(f"\nðŸ“¦ Original checkpoint: {len(state_dict)} keys")
    
    # Convert FP16 to FP32
    is_fp16 = False
    first_param = next(iter(state_dict.values()))
    if first_param.dtype == torch.float16:
        is_fp16 = True
        print(f"ðŸ” Converting FP16 â†’ FP32")
        state_dict = {k: v.float() if v.dtype == torch.float16 else v 
                     for k, v in state_dict.items()}
    
    adapted = {}
    adaptations = []
    
    print(f"\n{'='*70}")
    print("ðŸ”„ ADAPTING...")
    print(f"{'='*70}\n")
    
    # Process each key
    for key, value in state_dict.items():
        new_key = key
        new_value = value
        
        # 1. Handle BN fusion in decoder projections
        if '.bn.weight' in key or '.bn.bias' in key:
            # Skip BN keys - we'll fuse them
            continue
        
        # 2. For conv layers that had BN, fuse the BN
        if '.conv.weight' in key:
            base_key = key.replace('.conv.weight', '')
            bn_weight_key = f'{base_key}.bn.weight'
            bn_bias_key = f'{base_key}.bn.bias'
            
            if bn_weight_key in state_dict and bn_bias_key in state_dict:
                # This conv had a BN - fuse it
                conv_weight = value
                bn_weight = state_dict[bn_weight_key]
                bn_bias = state_dict[bn_bias_key]
                
                # Check for running stats (not always present)
                bn_mean_key = f'{base_key}.bn.running_mean'
                bn_var_key = f'{base_key}.bn.running_var'
                
                if bn_mean_key in state_dict and bn_var_key in state_dict:
                    bn_mean = state_dict[bn_mean_key]
                    bn_var = state_dict[bn_var_key]
                else:
                    # No running stats - use identity BN
                    bn_mean = torch.zeros_like(bn_weight)
                    bn_var = torch.ones_like(bn_weight)
                
                # Fuse
                fused_weight, fused_bias = fuse_bn_into_conv(
                    conv_weight, bn_weight, bn_bias, bn_mean, bn_var
                )
                
                # Store fused conv
                adapted[key] = fused_weight
                bias_key = key.replace('.weight', '.bias')
                adapted[bias_key] = fused_bias
                
                adaptations.append(f"Fused BN: {base_key}")
                continue
        
        # 3. Initialize fake_proj from corresponding proj layers
        # This is the KEY adaptation for your model
        if key == 'decode_head.decoder.c1_proj.conv.weight':
            # Also initialize fake_proj
            adapted['decode_head.c1_fake_proj.weight'] = value.clone()
            adaptations.append("Initialized c1_fake_proj from c1_proj")
        
        if key == 'decode_head.decoder.c2_proj.conv.weight':
            # Also initialize fake_proj
            adapted['decode_head.c2_fake_proj.weight'] = value.clone()
            adaptations.append("Initialized c2_fake_proj from c2_proj")
        
        # 4. Keep the original key
        adapted[new_key] = new_value
    
    print("âœ… Adaptations applied:")
    # Show unique adaptations
    unique_adaptations = list(set(adaptations))
    for adapt in unique_adaptations[:20]:
        print(f"  - {adapt}")
    if len(unique_adaptations) > 20:
        print(f"  ... and {len(unique_adaptations)-20} more")
    
    print(f"\nðŸ“Š Summary:")
    print(f"  Original keys:  {len(state_dict)}")
    print(f"  Adapted keys:   {len(adapted)}")
    print(f"  Added keys:     {len(adapted) - len(state_dict)}")
    
    # Save adapted checkpoint
    output_ckpt = {
        'model': adapted,
        'epoch': ckpt.get('epoch', 0),
        'best_miou': ckpt.get('best_miou', 0.0),
        'adapted': True,
        'original_fp16': is_fp16,
    }
    
    torch.save(output_ckpt, output_path)
    
    print(f"\n{'='*70}")
    print("âœ… ADAPTATION COMPLETE")
    print(f"{'='*70}")
    print(f"Saved: {output_path}")
    print(f"\nðŸ’¡ Now run evaluation with:")
    print(f"   python test.py --checkpoint {output_path} --val_txt <val.txt>")
    print(f"{'='*70}\n")


def main():
    parser = argparse.ArgumentParser(description="Adapt checkpoint to current model")
    
    parser.add_argument("--input", "-i", required=True,
                       help="Input checkpoint path")
    parser.add_argument("--output", "-o", required=True,
                       help="Output checkpoint path")
    
    args = parser.parse_args()
    
    adapt_checkpoint(args.input, args.output)


if __name__ == "__main__":
    main()
